library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
#Load Data
data <- read.csv('C:\\Users\\Harkirat Singh Lamba\\Desktop\\Topic Modeling_Phase3\\Combined_all.csv')
corpus <- corpus(data$Abstract)
tokens <- tokens(corpus)
toks <- tokens_select(tokens, pattern = stopwords("en"), selection = "remove")
toks <- tokens(toks, remove_punct = TRUE)
kw <- kwic(toks, pattern =  "library")
textplot_xray(
kwic(toks, pattern = "library"),
kwic(toks, pattern = "information"),
kwic(toks, pattern = "library science"),
kwic(toks, pattern = "information science")
)
#coloring
library("ggplot2")
theme_set(theme_bw())
g <- textplot_xray(
kwic(toks, pattern = "library"),
kwic(toks, pattern = "information"),
kwic(toks, pattern = "library science"),
kwic(toks, pattern = "information science")
)
g + aes(color = keyword) +
scale_color_manual(values = c("red", "red", "red", "red")) +
theme(legend.position = "none")
textplot_xray(
kwic(corpus, pattern = "library"),
kwic(corpus, pattern = "information"),
kwic(corpus, pattern = "library science"),
kwic(corpus, pattern = "information science")
)
library(tidyverse)
letters <- read_csv("C:\Users\Harkirat Singh Lamba\Desktop\Analysis_Phase1_Descriptive\doctorate_advisor.csv")
letters
letters <- read_csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\Analysis_Phase1_Descriptive\\doctorate_advisor.csv")
letters <- read_csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\Analysis_Phase1_Descriptive\\doctorate_advisor.csv")
letters
sources <- letters %>%
distinct(source) %>%
rename(label = source)
View(letters)
sources <- letters %>%
distinct(Advisor) %>%
rename(label = source)
Advisor <- letters %>%
distinct(Advisor) %>%
rename(label = Advisor)
View(Advisor)
ETD <- letters %>%
distinct(ETD) %>%
rename(label = ETD)
No._of_ETDs <- letters %>%
distinct(No._of_ETDs) %>%
rename(label = No._of_ETDs)
letters <- read_csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\Analysis_Phase1_Descriptive\\doctorate_advisor.csv")
letters
ETDs <- letters %>%
distinct(ETDs) %>%
rename(label = ETDs)
View(ETDs)
nodes <- full_join(Advisor, ETDs, by = "label")
nodes
nodes <- full_join(Advisor, ETDs, by = "label")
View(ETDs)
Advisor <- letters %>%
distinct(Advisor) %>%
rename(label = Degree2)
nodes <- full_join(Advisor, ETDs, by = "label")
library(tidyverse)
letters <- read_csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\advisor.csv")
letters
View(letters)
sources <- letters %>%
distinct(Advisor) %>%
rename(label = source)
Advisor <- letters %>%
distinct(Advisor) %>%
rename(label = Advisor)
View(Advisor)
S.No. <- letters %>%
distinct(S.No.) %>%
rename(label = S.No.)
View(S.No.)
nodes <- full_join(Advisor, S.No., by = "label")
nodes
View(nodes)
nodes <- nodes %>% rowid_to_column("id")
nodes
View(nodes)
per_route <- letters %>%
group_by(Advisor, S.No.) %>%
summarise(weight = n()) %>%
ungroup()
per_route
edges <- per_route %>%
left_join(nodes, by = c("source" = "label")) %>%
rename(from = id)
edges <- per_route %>%
left_join(nodes, by = c("Advisor" = "label")) %>%
rename(from = id)
edges <- edges %>%
left_join(nodes, by = c("S.No." = "label")) %>%
rename(to = id)
edges <- select(edges, from, to, weight)
edges
View(edges)
View(edges)
library(tidyverse)
letters <- read_csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\advisor.csv")
letters
#Node list
Advisor <- letters %>%
distinct(Advisor) %>%
rename(label = Advisor)
S.No. <- letters %>%
distinct(S.No.) %>%
rename(label = S.No.)
nodes <- full_join(Advisor, S.No., by = "label")
nodes
nodes <- nodes %>% rowid_to_column("id")
nodes
#Edge List
per_route <- letters %>%
group_by(Advisor, S.No.) %>%
summarise(weight = n()) %>%
ungroup()
per_route
edges <- per_route %>%
left_join(nodes, by = c("Advisor" = "label")) %>%
rename(from = id)
View(edges)
edges <- edges %>%
left_join(nodes, by = c("S.No." = "label")) %>%
rename(to = id)
View(edges)
edges <- write.csv(edges, edges.csv)
edges <- write.csv(edges, "edges.csv")
edges <- select(edges, from, to, weight)
edges
library(tidyverse)
letters <- read_csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\advisor.csv")
letters
#Node list
Advisor <- letters %>%
distinct(Advisor) %>%
rename(label = Advisor)
S.No. <- letters %>%
distinct(S.No.) %>%
rename(label = S.No.)
nodes <- full_join(Advisor, S.No., by = "label")
nodes
nodes <- nodes %>% rowid_to_column("id")
nodes
#Edge List
per_route <- letters %>%
group_by(Advisor, S.No.) %>%
summarise(weight = n()) %>%
ungroup()
per_route
edges <- per_route %>%
left_join(nodes, by = c("Advisor" = "label")) %>%
rename(from = id)
edges <- edges %>%
left_join(nodes, by = c("S.No." = "label")) %>%
rename(to = id)
edges <- select(edges, from, to, weight)
edges
View(edges)
library(visNetwork)
library(networkD3)
visNetwork(nodes, edges)
View(nodes)
library(network)
routes_network <- network(edges, vertex.attr = nodes, matrix.type = "edgelist", ignore.eval = FALSE)
class(routes_network)
routes_network
plot(routes_network, vertex.cex = 3)
plot(routes_network, vertex.cex = 3, mode = "circle")
View(edges)
library(visNetwork)
library(networkD3)
visNetwork(nodes, edges)
edges <- mutate(edges, width = weight/5 + 1)
visNetwork(nodes, edges) %>%
visIgraphLayout(layout = "layout_with_fr") %>%
visEdges(arrows = "middle")
file <- read.delim("G:\\Other computers\\Yoga Lenovo\\PhD\\Analysis+Data\\acknowledgement-main\\acknowledgement-main\\text\\query_1\\2000\\2001_1.txt")
file <- read.delim("G:\\PhD\\Analysis+Data\\acknowledgement-main\\acknowledgement-main\\text\\query_1\\2000\\2001_1.txt")
file <- read.delim("C:\\Users\\Harkirat Singh Lamba\\Desktop\\ff\\Author_Abstract\\2020_61.txt")
writeUtf8 <- function(x, file, bom=F) {
con <- file(file, "wb")
if(bom) writeBin(BOM, con, endian="little")
writeBin(charToRaw(x), con, endian="little")
close(con)
}
View(writeUtf8)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textstats)
data <- read.csv('C:\\Users\\Harkirat Singh Lamba\\Desktop\\Topic Modeling_Phase3\\Combined_all.csv')
corpus <- corpus(data$Abstract)
tokens <- tokens(corpus)
toks <- tokens_select(tokens, pattern = stopwords("en"), selection = "remove")
toks <- tokens(toks, remove_punct = TRUE)
kw <- kwic(toks, pattern =  "library")
textplot_xray(
kwic(toks, pattern = "library"),
kwic(toks, pattern = "information"),
kwic(toks, pattern = "library science"),
kwic(toks, pattern = "information science")
)
library("ggplot2")
theme_set(theme_bw())
g <- textplot_xray(
kwic(toks, pattern = "library"),
kwic(toks, pattern = "information"),
kwic(toks, pattern = "library science"),
kwic(toks, pattern = "information science")
)
library(keras)
library(keras)
install.packages("keras")
#Load data
c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()
#Load data
c(c(x_train, y_train), c(x_test, y_test)) %>% dataset_mnist()
library(keras)
#Load data
c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()
y
y
y
#Load data
c(c(x_train, y_train), c(x_test, y_test)) %<-% dataset_mnist()
yyy
y
#Load data
data = read.csv('"C:\\Users\\Harkirat Singh Lamba\\Desktop\\Topic Modeling_Phase3\\BertTopic\\2000s\\2000s.csv"')
#Load data
data = read.csv('C:\\Users\\Harkirat Singh Lamba\\Desktop\\Topic Modeling_Phase3\\BertTopic\\2000s\\2000s.csv')
data2 = c(c(x_train, y_train), c(x_test, y_test))
data2 = c(c(degree2, abstract), c(degree2, abstract))
data2 = c(c(data$degree2, data$abstract), c(data$degree2, data$abstract))
library(syuzhet)
library(tm)
library(twitteR)
install.packages("syuzhet")
library(syuzhet)
library(tm)
#Load dataset
data<- read.csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\cafe_sentiment.csv")
#Avoid error related to tolower() invalid multibyte string
data[,sapply(data,is.character)] <- sapply(
data[,sapply(data,is.character)],
iconv,"WINDOWS-1252","UTF-8")
#syuzhet package works only on vectors. So, the data was converted to a vector
vector <- as.vector(t(data))
#Sentiment analysis
emotion.data <- get_nrc_sentiment(vector)
emotion.data2 <- cbind(data, emotion.data)
sentiment.score <- get_sentiment(vector)
sentiment.data = cbind(sentiment.score, emotion.data2)
#Getting positive, negative, and neutral reviews with associated scores
positive.reviews <- sentiment.data[which(sentiment.data$sentiment.score > 0),]
write.csv(positive.reviews, "positive.reviews.csv")
negative.reviews <- sentiment.data[which(sentiment.data$sentiment.score < 0),]
write.csv(negative.reviews, "negative.reviews.csv")
neutral.reviews <- sentiment.data[which(sentiment.data$sentiment.score == 0),]
write.csv(neutral.reviews, "neutral.reviews.csv")
#Plot1: Percentage-Based Means
percent_vals <- get_percentage_values(sentiment.score, bins=20)
#Plot1: Percentage-Based Means
percent_vals <- get_percentage_values(sentiment.score, bins=5)
#Plot1: Percentage-Based Means
percent_vals <- get_percentage_values(sentiment.score, bins=0.1)
#Plot1: Percentage-Based Means
percent_vals <- get_percentage_values(sentiment.score, bins=1)
#Plot1: Percentage-Based Means
percent_vals <- get_percentage_values(sentiment.score)
#Plot1: Percentage-Based Means
percent_vals <- get_percentage_values(sentiment.score, bins=2)
plot(percent_vals,
type="l",
main="Amazon Book Reviews using Percentage-Based Means",
xlab="Narrative Time",
ylab="Emotional Valence",
col="red")
#Plot2: Discrete Cosine Transformation (DCT)
dct_values <- get_dct_transform(sentiment.score,
low_pass_size = 5,
x_reverse_len = 100,
scale_vals = F,
scale_range = T)
plot(dct_values,
type ="l",
main ="Amazon Book Reviews using Transformed Values",
xlab = "Narrative Time",
ylab = "Emotional Valence",
col = "red")
#Plot3: Emotions Graph
barplot(sort(colSums(prop.table(emotion.data[, 1:8]))),
horiz=TRUE,
cex.names=0.7,
las=1,
main="Emotions in Amazon Book Reviews",
xlab = "Percentage")
#Plot3: Emotions Graph
barplot(sort(colSums(prop.table(emotion.data[, 1:8]))),
horiz=TRUE,
cex.names=0.7,
las=1,
main="Emotions in CAfe Meet Feedback",
xlab = "Percentage")
#Plot3: Emotions Graph
barplot(sort(colSums(prop.table(emotion.data[, 1:8]))),
horiz=TRUE,
cex.names=0.7,
las=1,
main="Emotions in Cafe Meet Feedback",
xlab = "Percentage")
#Plot3: Emotions Graph
barplot(sort(colSums(prop.table(emotion.data[, 1:8]))),
horiz=TRUE,
cex.names=0.7,
las=1,
main="Emotions in SIG III Cafe Meet Feedback",
xlab = "Percentage")
plot(dct_values,
type ="l",
main ="SIG III Cafe Meet Feedback using Transformed Values",
xlab = "Narrative Time",
ylab = "Emotional Valence",
col = "red")
shiny::runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
shiny::runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
View(data)
g <-  read_graph('C:\\Users\\Harkirat Singh Lamba\\Desktop\\yt\\filter_bubbles.gml', format = "gml")
input_file <- as_data_frame(g,"vertices")
View(input_file)
runApp('C:/Users/Harkirat Singh Lamba/Desktop/yt')
data <- "C:\\Users\\Harkirat Singh Lamba\\Desktop\\Topic Modeling_Phase3\\BertTopic\\Searchable database FINAL results\\Try 1.csv"
data <- "C:\\Users\\Harkirat Singh Lamba\\Desktop\\Topic Modeling_Phase3\\BertTopic\\Searchable database FINAL results\\Try 1.csv"
data <- read.csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\Topic Modeling_Phase3\\BertTopic\\Searchable database FINAL results\\Try 1.csv")
View(data)
df <- data.frame(data)
View(df)
library(shiny); runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
View(df)
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
names(df)
names(data)
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
data <- read.csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\Topic Modeling_Phase3\\BertTopic\\Searchable database FINAL results\\Try 1.csv")
df <- data.frame(data)
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
runApp('C:/Users/Harkirat Singh Lamba/Desktop/Topic Modeling_Phase3/BertTopic/Searchable database FINAL results/shiny app.R')
library(bibliometrix)
biblioshiny()
biblioshiny()
library(bibliometrix)
scopus <- convert2df("C:\Users\Harkirat Singh Lamba\Desktop\WDL.csv", dbsource = "scopus", format = "csv")
scopus <- convert2df("C:\\Users\\Harkirat Singh Lamba\\Desktop\\WDL.csv", dbsource = "scopus", format = "csv")
scopus <- convert2df("C:\\Users\\Harkirat Singh Lamba\\Desktop\\WDL.csv", dbsource = "scopus", format = "csv")
scopus <- convert2df("C:\\Users\\Harkirat Singh Lamba\\Desktop\\WDL.bib", dbsource = "scopus", format = "bibtex")
scopus <- convert2df("C:\\Users\\Harkirat Singh Lamba\\Desktop\WDL.csv", dbsource = "scopus", format = "csv")
scopus <- convert2df("C:\\Users\\Harkirat Singh Lamba\\Desktop\\WDL.csv", dbsource = "scopus", format = "csv")
library(readr)
library(tidyr)
library(dplyr)
library(tm)
library(wordcloud2)
library(networkD3)
mybib= read_csv("C:\\Users\\Harkirat Singh Lamba\\Desktop\\WDL2.csv")
data.frame(colnames(mybib))
dim(mybib)
#authorship pattern
authoship_pattern=table(as.data.frame(count.fields(textConnection(mybib$Author), sep = ";")))
View(authoship_pattern)
write.csv(authoship_pattern, "authorship_pattern.csv")
#Finding the document types
table(mybib$`Item Type`)
#wordcloud
wc=data.frame(mybib$`Abstract Note`)
modified_wc=wc[rowSums(is.na(wc)) != ncol(wc),]
View(modified_wc)
text= Corpus(VectorSource(modified_wc))
myStopwords <- c("topic", "topics", "using", "library")
tdm = TermDocumentMatrix(text, control = list(removePunctuation = TRUE, stopwords = TRUE))
tdm = as.matrix(tdm)
terms = sort(rowSums(tdm),decreasing=TRUE)
finalDf = data.frame(word = names(terms),freq=terms)
head(finalDf)
wordcloud2(data=finalDf)
#network author-year
network=data.frame(mybib$`Publication Year`,mybib$Author)
simpleNetwork(network)
#network
network=data.frame(mybib$`Publication Year`,mybib$`Publication Title`)
simpleNetwork(network)
setwd("C:/Users/Harkirat Singh Lamba/Desktop/Papers_PhD/AIIMS_COVID")
setwd("C:/Users/Harkirat Singh Lamba/Downloads/rladies-nyc-codebook-comparison-main")
setwd("C:/Users/Harkirat Singh Lamba/Desktop/Papers_PhD/AIIMS-COVID_Presentation_SIS.2022")
library(shiny); runApp('D:/2021/MASTER/DASHBOARD/pqdt.R')
library(flexdashboard)
library(gt)
library(tidyverse)
df <- tibble(
Journals = c("INDIAN JOURNAL OF PALLIATIVE CARE", "INDIAN JOURNAL OF OPHTHALMOLOGY", "INDIAN JOURNAL OF NEPHROLOGY", "INDIAN JOURNAL OF MEDICAL RESEARCH", "INDIAN PEDIATRICS", "DIABETES AND METABOLIC SYNDROME: CLINICAL RESEARCH AND REVIEWS", "INDIAN HEART JOURNAL", "INDIAN JOURNAL OF MEDICAL AND PAEDIATRIC ONCOLOGY", "JOURNAL OF FAMILY MEDICINE AND PRIMARY CARE"),
Articles = c("23", "21", "13", "12", "11", "10", "7", "7", "7"),
)
df %>%
gt()
setwd("~/GitHub/SIS")
setwd("~/GitHub/SIS")
